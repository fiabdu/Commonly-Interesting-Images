{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import gdown\n",
    "import clip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import requests\n",
    "from IPython.display import display\n",
    "\n",
    "# Used for visualization purposes\n",
    "size_ = 512 \n",
    "resize = transforms.Resize(size_)\n",
    "center_crop = transforms.CenterCrop(size_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset (flickrUser_definition.csv) from the following link (skip if you already have the dataset):\n",
    "file_id = '1wX8Ti3opqCS_AnXU88sixHElbcS_Lj03'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "# The file will be saved as 'flickrUser_definition.csv'\n",
    "output = 'flickrUser_definition.csv'\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_definition = pd.read_csv('flickrUser_definition.csv')\n",
    "df_definition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-driven Definition of Common Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Interestingness (cf. Figure 2)\n",
    "unique_users = df_definition.groupby(['partition'])['user_id'].nunique().reset_index(name='unique_users')\n",
    "unique_users.sort_values(by='unique_users', ascending=False, inplace=True)\n",
    "unique_users.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Bar plot of unique users per partition\n",
    "unique_users['unique_users'].plot(kind='bar', figsize=(20, 5))\n",
    "plt.xlabel('Partition')\n",
    "plt.ylabel('Unique Users')\n",
    "plt.xticks(ticks=np.arange(0, len(unique_users), 1), labels=unique_users['partition'])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Makes an Image Commonly Interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into three groups based on the trend_group\n",
    "df_common = df_definition[(df_definition['trend_group'] == 0)]\n",
    "df_interplay = df_definition[(df_definition['trend_group'] == 1)]\n",
    "df_subjective = df_definition[(df_definition['trend_group'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptual Features (cf. Table 1)\n",
    "perceptual_features_common = df_common.value_counts(subset = ['VILA_main_feature'], normalize=True).round(4) * 100\n",
    "aesthetic_score_common = df_common['VILA_aesthetic_score'].describe()[['25%', '50%', '75%']].round(4) * 100\n",
    "\n",
    "perceptual_features_interplay = df_interplay.value_counts(subset = ['VILA_main_feature'], normalize=True).round(4) * 100\n",
    "aesthetic_score_interplay = df_interplay['VILA_aesthetic_score'].describe()[['25%', '50%', '75%']].round(4) * 100\n",
    "\n",
    "perceptual_features_subjective = df_subjective.value_counts(subset = ['VILA_main_feature'], normalize=True).round(4) * 100\n",
    "aesthetic_score_subjective = df_subjective['VILA_aesthetic_score'].describe()[['25%', '50%', '75%']].round(4) * 100\n",
    "\n",
    "df_perceptual_features = pd.concat([perceptual_features_common, perceptual_features_interplay, perceptual_features_subjective], axis=1)\n",
    "df_perceptual_features.columns = ['Common', 'Interplay', 'Subjective']\n",
    "df_perceptual_features['Delta'] = df_perceptual_features['Common'] - df_perceptual_features['Subjective']\n",
    "df_perceptual_features.sort_values(by='Delta', ascending=False, inplace=True)\n",
    "df_perceptual_features.index.names = ['Scores from VILA']\n",
    "display(df_perceptual_features)\n",
    "\n",
    "df_aesthetic_score = pd.concat([aesthetic_score_common, aesthetic_score_interplay, aesthetic_score_subjective], axis=1)\n",
    "df_aesthetic_score.columns = ['Common', 'Interplay', 'Subjective']\n",
    "df_aesthetic_score['Delta'] = df_aesthetic_score['Common'] - df_aesthetic_score['Subjective']\n",
    "df_aesthetic_score.index.names = ['Scores from VILA']\n",
    "display(df_aesthetic_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the owner of the image is a photographer\n",
    "is_photographer = []\n",
    "for i in df_definition.index:\n",
    "    if 'photographer' in str(df_definition.loc[i, 'favimg_owner_occupation']).lower():\n",
    "        is_photographer.append(1)\n",
    "        # print(df.loc[i, 'img_owner_occupation'])\n",
    "    else:\n",
    "        is_photographer.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'is_photographer' column to the dataset\n",
    "df_photographer = df_definition.copy()\n",
    "df_photographer['is_photographer'] = is_photographer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of photographers in each group\n",
    "df_temp = df_photographer[df_photographer['trend_group'] == 0]\n",
    "group_0_val = df_temp.value_counts(subset = ['is_photographer'], normalize=True).round(4) * 100\n",
    "print(f'Photographers in common interesting group: {group_0_val[1]}%')\n",
    "\n",
    "df_temp = df_photographer[df_photographer['trend_group'] == 1]\n",
    "group_1_val = df_temp.value_counts(subset = ['is_photographer'], normalize=True).round(4) * 100\n",
    "print(f'Photographers in interplay group: {group_1_val[1]}%')\n",
    "\n",
    "df_temp = df_photographer[df_photographer['trend_group'] == 2]\n",
    "group_2_val = df_temp.value_counts(subset = ['is_photographer'], normalize=True).round(4) * 100\n",
    "print(f'Photographers in subjective interesting group: {group_2_val[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connotative Features (cf. Table 3)\n",
    "connotative_features_common = df_common.value_counts(subset = ['CLIP_emotion_main_category'], normalize=True).round(4) * 100\n",
    "connotative_features_interplay = df_interplay.value_counts(subset = ['CLIP_emotion_main_category'], normalize=True).round(4) * 100\n",
    "connotative_features_subjective = df_subjective.value_counts(subset = ['CLIP_emotion_main_category'], normalize=True).round(4) * 100\n",
    "\n",
    "connotative_features_positive = ['excitement', 'awe', 'contentment', 'amusement']\n",
    "connotative_features_negative = ['sadness', 'disgust', 'anger', 'fear']\n",
    "\n",
    "df_connotative_features_positive = pd.concat([connotative_features_common[connotative_features_positive], connotative_features_interplay[connotative_features_positive], connotative_features_subjective[connotative_features_positive]], axis=1)\n",
    "df_connotative_features_positive.columns = ['Common', 'Interplay', 'Subjective']\n",
    "df_connotative_features_positive.index = ['Excitement', 'Awe', 'Contentment', 'Amusement']\n",
    "df_connotative_features_positive['Delta'] = df_connotative_features_positive['Common'] - df_connotative_features_positive['Subjective']\n",
    "df_connotative_features_positive.sort_values(by='Delta', ascending=False, inplace=True)\n",
    "df_connotative_features_positive.loc['Sum Positive'] = df_connotative_features_positive.sum()\n",
    "df_connotative_features_positive.index.names = ['Scores from CLIP']\n",
    "display(df_connotative_features_positive)\n",
    "\n",
    "df_connotative_features_negative = pd.concat([connotative_features_common[connotative_features_negative], connotative_features_interplay[connotative_features_negative], connotative_features_subjective[connotative_features_negative]], axis=1)\n",
    "df_connotative_features_negative.columns = ['Common', 'Interplay', 'Subjective']\n",
    "df_connotative_features_negative.index = ['Sadness', 'Disgust', 'Anger', 'Fear']\n",
    "df_connotative_features_negative['Delta'] = df_connotative_features_negative['Common'] - df_connotative_features_negative['Subjective']\n",
    "df_connotative_features_negative.sort_values(by='Delta', ascending=False, inplace=True)\n",
    "df_connotative_features_negative.loc['Sum Negative'] = df_connotative_features_negative.sum()\n",
    "df_connotative_features_negative.index.names = ['Scores from CLIP']\n",
    "display(df_connotative_features_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Model of Common Interestingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FlickrUser Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset (flickrUser_additional.csv) from the following link (skip if you already have the dataset):\n",
    "file_id = '1j8J6i14MqyRtlwPGPfNC5lxqIzX_e1N_'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "# The file will be saved as 'flickrUser.csv'\n",
    "output = 'flickrUser_additional.csv'\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_additional = pd.read_csv('flickrUser_additional.csv')\n",
    "df_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User examples (cf. Figure 7)\n",
    "user_id = '130140542@N03'\n",
    "df_user = df_additional[df_additional['user_id'] == user_id]\n",
    "df_user_common = df_user[df_user['ci_r_score'] > 0.6].sample(n=3)\n",
    "df_user_interplay = df_user[(df_user['ci_r_score'] < 0.3) & (df_user['ci_r_score'] > 0.2)].sample(n=3)\n",
    "df_user_subjective = df_user[df_user['ci_r_score'] < 0.1].sample(n=3)\n",
    "\n",
    "df_user_trends = pd.concat([df_user_common, df_user_interplay, df_user_subjective])\n",
    "df_user_trends.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Open image url and display it\n",
    "def open_image_url(url):\n",
    "    img = Image.open(requests.get(url, stream=True).raw)\n",
    "    img = center_crop(resize(img))\n",
    "    return img\n",
    "\n",
    "# Display the images\n",
    "fig, ax = plt.subplots(1, 9, figsize=(15, 5))\n",
    "for i in range(9):\n",
    "    img = open_image_url(df_user_trends.loc[i, 'favimg_url'])\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(f'CI_R Score: {df_user_trends.loc[i, \"ci_r_score\"]:.3f}', fontsize=10)\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel(f'{user_id}', fontsize=10, fontweight='bold')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use your own Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "\n",
    "# Define the CI_R model\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(768, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Load the CI_R model\n",
    "model_ci_r = RegressionModel().to(device)\n",
    "model_ci_r.load_state_dict(torch.load('CI_R_model.pth'))\n",
    "model_ci_r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image path for the sample images\n",
    "img_path_libertyStatue = [os.path.join('./sampleImages/libertyStatue/', img_path) for img_path in os.listdir('./sampleImages/libertyStatue/')]\n",
    "img_path_eiffelTower = [os.path.join('./sampleImages/eiffelTower/', img_path) for img_path in os.listdir('./sampleImages/eiffelTower/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from the images\n",
    "image_features_libertyStatue = []\n",
    "image_features_eiffelTower = []\n",
    "for i in range(len(img_path_libertyStatue)):\n",
    "    image_libertyStatue = preprocess(Image.open(img_path_libertyStatue[i])).unsqueeze(0).to('cuda')\n",
    "    image_eiffelTower = preprocess(Image.open(img_path_eiffelTower[i])).unsqueeze(0).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        image_features_libertyStatue.append(model.encode_image(image_libertyStatue))\n",
    "        image_features_eiffelTower.append(model.encode_image(image_eiffelTower))\n",
    "\n",
    "image_features_libertyStatue = [image_feature.cpu().detach().numpy() for image_feature in image_features_libertyStatue]\n",
    "image_features_libertyStatue = np.array(image_features_libertyStatue).reshape(len(image_features_libertyStatue), -1)\n",
    "\n",
    "image_features_eiffelTower = [image_feature.cpu().detach().numpy() for image_feature in image_features_eiffelTower]\n",
    "image_features_eiffelTower = np.array(image_features_eiffelTower).reshape(len(image_features_eiffelTower), -1)\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(f'Image features (Liberty Statue): {image_features_libertyStatue.shape}')\n",
    "print(f'Image features (Eiffel Tower): {image_features_eiffelTower.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the CI_R score\n",
    "ci_score_libertyStatue = model_ci_r(torch.tensor(image_features_libertyStatue, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()\n",
    "ci_score_eiffelTower = model_ci_r(torch.tensor(image_features_eiffelTower, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()\n",
    "\n",
    "# Create a dataframe with the image paths and their CI scores\n",
    "df_ci_score_libertyStatue = pd.DataFrame({'img_path': img_path_libertyStatue, 'ci_score': ci_score_libertyStatue})\n",
    "df_ci_score_libertyStatue.sort_values(by='ci_score', ascending=False, inplace=True)\n",
    "df_ci_score_eiffelTower = pd.DataFrame({'img_path': img_path_eiffelTower, 'ci_score': ci_score_eiffelTower})\n",
    "df_ci_score_eiffelTower.sort_values(by='ci_score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the images with their CI scores (cf. Figure 6)\n",
    "fig, ax = plt.subplots(1, df_ci_score_eiffelTower.shape[0], figsize=(15, 5))\n",
    "for i in range(df_ci_score_eiffelTower.shape[0]):\n",
    "    img = Image.open(df_ci_score_eiffelTower['img_path'].iloc[i])\n",
    "    ax[i].imshow(center_crop(resize(img)))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(f'CI_R Score: {df_ci_score_eiffelTower[\"ci_score\"].iloc[i]:.3f}', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, df_ci_score_libertyStatue.shape[0], figsize=(15, 5))\n",
    "for i in range(df_ci_score_libertyStatue.shape[0]):\n",
    "    img = Image.open(df_ci_score_libertyStatue['img_path'].iloc[i])\n",
    "    ax[i].imshow(center_crop(resize(img)))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(f'CI_R Score: {df_ci_score_libertyStatue[\"ci_score\"].iloc[i]:.3f}', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapidsai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
